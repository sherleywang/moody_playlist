{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0frxtq7P3N1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53371257-3fdf-41d7-f58a-21dd83582f4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1r1JhWuH1ar"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pickle\n",
        "from sklearn import pipeline\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn import ensemble\n",
        "from sklearn import neural_network\n",
        "from sklearn import decomposition"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94cPfr72HqAQ"
      },
      "source": [
        "raw_features_path = \"/content/drive/MyDrive/moody_playlist_data/raw_features.csv\"\n",
        "raw_features = pd.read_csv(raw_features_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2RAS77aMEPw"
      },
      "source": [
        "basic_features_path = \"/content/drive/MyDrive/moody_playlist_data/features.csv\"\n",
        "basic_features = pd.read_csv(basic_features_path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4-0xIcOJyLi",
        "outputId": "12480947-d804-4943-a728-a1054e3b4303"
      },
      "source": [
        "combined_raw = pd.concat([basic_features, raw_features], axis = 1)\n",
        "combined_raw['song_check'] = combined_raw['title'] + ' - ' + combined_raw['artist']\n",
        "if combined_raw['song'].equals(combined_raw['song_check']):\n",
        "    print (\"Raw features match.\")\n",
        "    combined_raw = combined_raw.drop(columns = ['song', 'song_check'])\n",
        "else:\n",
        "    print (\"Raw features DO NOT match.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw features match.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "cyeeWS0kOYuI",
        "outputId": "660a7c17-45cc-4172-e480-f30669dade43"
      },
      "source": [
        "combined_raw"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>artist</th>\n",
              "      <th>tempo</th>\n",
              "      <th>chroma_number</th>\n",
              "      <th>zero_crossing_rate</th>\n",
              "      <th>energy_entropy</th>\n",
              "      <th>spectral_centroid</th>\n",
              "      <th>primary</th>\n",
              "      <th>secondary</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>...</th>\n",
              "      <th>99960</th>\n",
              "      <th>99961</th>\n",
              "      <th>99962</th>\n",
              "      <th>99963</th>\n",
              "      <th>99964</th>\n",
              "      <th>99965</th>\n",
              "      <th>99966</th>\n",
              "      <th>99967</th>\n",
              "      <th>99968</th>\n",
              "      <th>99969</th>\n",
              "      <th>99970</th>\n",
              "      <th>99971</th>\n",
              "      <th>99972</th>\n",
              "      <th>99973</th>\n",
              "      <th>99974</th>\n",
              "      <th>99975</th>\n",
              "      <th>99976</th>\n",
              "      <th>99977</th>\n",
              "      <th>99978</th>\n",
              "      <th>99979</th>\n",
              "      <th>99980</th>\n",
              "      <th>99981</th>\n",
              "      <th>99982</th>\n",
              "      <th>99983</th>\n",
              "      <th>99984</th>\n",
              "      <th>99985</th>\n",
              "      <th>99986</th>\n",
              "      <th>99987</th>\n",
              "      <th>99988</th>\n",
              "      <th>99989</th>\n",
              "      <th>99990</th>\n",
              "      <th>99991</th>\n",
              "      <th>99992</th>\n",
              "      <th>99993</th>\n",
              "      <th>99994</th>\n",
              "      <th>99995</th>\n",
              "      <th>99996</th>\n",
              "      <th>99997</th>\n",
              "      <th>99998</th>\n",
              "      <th>99999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a new adventure</td>\n",
              "      <td>takanashi yasuharu</td>\n",
              "      <td>117.453835</td>\n",
              "      <td>-0.010635</td>\n",
              "      <td>0.082014</td>\n",
              "      <td>3.164051</td>\n",
              "      <td>0.186062</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.133759</td>\n",
              "      <td>0.116821</td>\n",
              "      <td>0.142548</td>\n",
              "      <td>0.124207</td>\n",
              "      <td>0.009430</td>\n",
              "      <td>0.067474</td>\n",
              "      <td>0.181488</td>\n",
              "      <td>0.219666</td>\n",
              "      <td>0.106842</td>\n",
              "      <td>-0.174561</td>\n",
              "      <td>-0.307129</td>\n",
              "      <td>-0.324890</td>\n",
              "      <td>-0.083984</td>\n",
              "      <td>-0.002960</td>\n",
              "      <td>0.092987</td>\n",
              "      <td>-0.013733</td>\n",
              "      <td>-0.183990</td>\n",
              "      <td>-0.217865</td>\n",
              "      <td>-0.216522</td>\n",
              "      <td>-0.159241</td>\n",
              "      <td>-0.160767</td>\n",
              "      <td>0.085083</td>\n",
              "      <td>0.043732</td>\n",
              "      <td>-0.120087</td>\n",
              "      <td>-0.259277</td>\n",
              "      <td>-0.099213</td>\n",
              "      <td>-0.188293</td>\n",
              "      <td>0.012268</td>\n",
              "      <td>0.029846</td>\n",
              "      <td>0.010315</td>\n",
              "      <td>-0.001953</td>\n",
              "      <td>...</td>\n",
              "      <td>0.155273</td>\n",
              "      <td>0.184082</td>\n",
              "      <td>0.053253</td>\n",
              "      <td>0.086792</td>\n",
              "      <td>0.202667</td>\n",
              "      <td>0.119232</td>\n",
              "      <td>-0.093842</td>\n",
              "      <td>-0.065155</td>\n",
              "      <td>0.147888</td>\n",
              "      <td>0.196228</td>\n",
              "      <td>0.130829</td>\n",
              "      <td>-0.006805</td>\n",
              "      <td>0.082336</td>\n",
              "      <td>-0.111420</td>\n",
              "      <td>-0.269745</td>\n",
              "      <td>-0.052246</td>\n",
              "      <td>-0.124756</td>\n",
              "      <td>0.009796</td>\n",
              "      <td>-0.174103</td>\n",
              "      <td>-0.352661</td>\n",
              "      <td>-0.272919</td>\n",
              "      <td>-0.187561</td>\n",
              "      <td>-0.075317</td>\n",
              "      <td>-0.010376</td>\n",
              "      <td>-0.072021</td>\n",
              "      <td>-0.007263</td>\n",
              "      <td>-0.077972</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>0.033020</td>\n",
              "      <td>-0.133118</td>\n",
              "      <td>-0.080841</td>\n",
              "      <td>-0.034271</td>\n",
              "      <td>-0.182251</td>\n",
              "      <td>0.017303</td>\n",
              "      <td>0.132935</td>\n",
              "      <td>0.306610</td>\n",
              "      <td>0.148407</td>\n",
              "      <td>-0.014404</td>\n",
              "      <td>0.183716</td>\n",
              "      <td>0.136566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a oh</td>\n",
              "      <td>super junior</td>\n",
              "      <td>129.199219</td>\n",
              "      <td>-0.005782</td>\n",
              "      <td>0.078039</td>\n",
              "      <td>3.213386</td>\n",
              "      <td>0.179459</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.036011</td>\n",
              "      <td>0.041168</td>\n",
              "      <td>0.049866</td>\n",
              "      <td>0.052704</td>\n",
              "      <td>0.049591</td>\n",
              "      <td>0.041840</td>\n",
              "      <td>0.034576</td>\n",
              "      <td>0.038391</td>\n",
              "      <td>0.046722</td>\n",
              "      <td>0.044220</td>\n",
              "      <td>0.036621</td>\n",
              "      <td>0.046051</td>\n",
              "      <td>0.067596</td>\n",
              "      <td>0.075500</td>\n",
              "      <td>0.066803</td>\n",
              "      <td>0.056213</td>\n",
              "      <td>0.044464</td>\n",
              "      <td>0.037018</td>\n",
              "      <td>0.043945</td>\n",
              "      <td>0.059082</td>\n",
              "      <td>0.066772</td>\n",
              "      <td>0.060669</td>\n",
              "      <td>0.048828</td>\n",
              "      <td>0.041412</td>\n",
              "      <td>0.026337</td>\n",
              "      <td>-0.007507</td>\n",
              "      <td>-0.038635</td>\n",
              "      <td>-0.045898</td>\n",
              "      <td>-0.034515</td>\n",
              "      <td>-0.024139</td>\n",
              "      <td>-0.036530</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010681</td>\n",
              "      <td>0.027618</td>\n",
              "      <td>0.029266</td>\n",
              "      <td>0.003479</td>\n",
              "      <td>-0.031036</td>\n",
              "      <td>-0.017517</td>\n",
              "      <td>-0.049591</td>\n",
              "      <td>-0.036987</td>\n",
              "      <td>0.035645</td>\n",
              "      <td>0.022614</td>\n",
              "      <td>-0.110046</td>\n",
              "      <td>-0.171906</td>\n",
              "      <td>-0.134247</td>\n",
              "      <td>-0.031189</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>-0.045563</td>\n",
              "      <td>-0.089325</td>\n",
              "      <td>0.014465</td>\n",
              "      <td>0.117493</td>\n",
              "      <td>0.098602</td>\n",
              "      <td>0.046997</td>\n",
              "      <td>-0.011322</td>\n",
              "      <td>-0.070007</td>\n",
              "      <td>-0.050446</td>\n",
              "      <td>-0.013580</td>\n",
              "      <td>-0.082764</td>\n",
              "      <td>-0.140228</td>\n",
              "      <td>-0.126617</td>\n",
              "      <td>-0.130219</td>\n",
              "      <td>-0.094116</td>\n",
              "      <td>-0.007111</td>\n",
              "      <td>-0.030304</td>\n",
              "      <td>-0.008392</td>\n",
              "      <td>0.059509</td>\n",
              "      <td>0.092468</td>\n",
              "      <td>0.025116</td>\n",
              "      <td>0.016785</td>\n",
              "      <td>0.041809</td>\n",
              "      <td>0.071136</td>\n",
              "      <td>0.130554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a thousand years</td>\n",
              "      <td>christina perri</td>\n",
              "      <td>92.285156</td>\n",
              "      <td>-0.016321</td>\n",
              "      <td>0.044617</td>\n",
              "      <td>3.217903</td>\n",
              "      <td>0.122203</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0.055420</td>\n",
              "      <td>0.006805</td>\n",
              "      <td>-0.044891</td>\n",
              "      <td>-0.095825</td>\n",
              "      <td>-0.134277</td>\n",
              "      <td>-0.156830</td>\n",
              "      <td>-0.174744</td>\n",
              "      <td>-0.179108</td>\n",
              "      <td>-0.175995</td>\n",
              "      <td>-0.170349</td>\n",
              "      <td>-0.161591</td>\n",
              "      <td>-0.155548</td>\n",
              "      <td>-0.160583</td>\n",
              "      <td>-0.165436</td>\n",
              "      <td>-0.157532</td>\n",
              "      <td>-0.139526</td>\n",
              "      <td>-0.116089</td>\n",
              "      <td>-0.094452</td>\n",
              "      <td>-0.081116</td>\n",
              "      <td>-0.073120</td>\n",
              "      <td>-0.055878</td>\n",
              "      <td>-0.020569</td>\n",
              "      <td>0.023346</td>\n",
              "      <td>0.065613</td>\n",
              "      <td>0.107117</td>\n",
              "      <td>0.149323</td>\n",
              "      <td>0.186401</td>\n",
              "      <td>0.205780</td>\n",
              "      <td>0.205505</td>\n",
              "      <td>0.196716</td>\n",
              "      <td>0.188049</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>-0.063721</td>\n",
              "      <td>-0.055878</td>\n",
              "      <td>-0.048798</td>\n",
              "      <td>-0.043335</td>\n",
              "      <td>-0.038116</td>\n",
              "      <td>-0.034332</td>\n",
              "      <td>-0.029358</td>\n",
              "      <td>-0.024780</td>\n",
              "      <td>-0.020721</td>\n",
              "      <td>-0.021881</td>\n",
              "      <td>-0.022247</td>\n",
              "      <td>-0.022034</td>\n",
              "      <td>-0.022125</td>\n",
              "      <td>-0.025269</td>\n",
              "      <td>-0.027222</td>\n",
              "      <td>-0.027863</td>\n",
              "      <td>-0.029541</td>\n",
              "      <td>-0.029785</td>\n",
              "      <td>-0.026886</td>\n",
              "      <td>-0.022827</td>\n",
              "      <td>-0.021790</td>\n",
              "      <td>-0.023651</td>\n",
              "      <td>-0.029633</td>\n",
              "      <td>-0.037109</td>\n",
              "      <td>-0.046234</td>\n",
              "      <td>-0.053772</td>\n",
              "      <td>-0.059326</td>\n",
              "      <td>-0.061462</td>\n",
              "      <td>-0.061310</td>\n",
              "      <td>-0.058014</td>\n",
              "      <td>-0.056671</td>\n",
              "      <td>-0.054871</td>\n",
              "      <td>-0.055237</td>\n",
              "      <td>-0.053772</td>\n",
              "      <td>-0.048981</td>\n",
              "      <td>-0.044281</td>\n",
              "      <td>-0.034943</td>\n",
              "      <td>-0.029633</td>\n",
              "      <td>-0.027527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>adore u</td>\n",
              "      <td>seventeen</td>\n",
              "      <td>103.359375</td>\n",
              "      <td>-0.007745</td>\n",
              "      <td>0.058125</td>\n",
              "      <td>3.142738</td>\n",
              "      <td>0.145660</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.197845</td>\n",
              "      <td>-0.249542</td>\n",
              "      <td>-0.231934</td>\n",
              "      <td>-0.196228</td>\n",
              "      <td>-0.125092</td>\n",
              "      <td>0.024902</td>\n",
              "      <td>0.097107</td>\n",
              "      <td>0.132629</td>\n",
              "      <td>0.159119</td>\n",
              "      <td>0.110992</td>\n",
              "      <td>0.063507</td>\n",
              "      <td>0.015350</td>\n",
              "      <td>-0.012024</td>\n",
              "      <td>0.025635</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>0.010620</td>\n",
              "      <td>-0.079895</td>\n",
              "      <td>-0.089844</td>\n",
              "      <td>-0.075348</td>\n",
              "      <td>-0.156830</td>\n",
              "      <td>-0.126526</td>\n",
              "      <td>-0.172668</td>\n",
              "      <td>-0.194214</td>\n",
              "      <td>-0.089844</td>\n",
              "      <td>0.004517</td>\n",
              "      <td>-0.005066</td>\n",
              "      <td>0.084961</td>\n",
              "      <td>-0.028473</td>\n",
              "      <td>-0.156372</td>\n",
              "      <td>-0.102722</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045868</td>\n",
              "      <td>0.125397</td>\n",
              "      <td>-0.179932</td>\n",
              "      <td>0.108307</td>\n",
              "      <td>-0.221252</td>\n",
              "      <td>0.195251</td>\n",
              "      <td>0.000946</td>\n",
              "      <td>0.014099</td>\n",
              "      <td>-0.194092</td>\n",
              "      <td>-0.185425</td>\n",
              "      <td>0.241699</td>\n",
              "      <td>0.025299</td>\n",
              "      <td>-0.042542</td>\n",
              "      <td>-0.114655</td>\n",
              "      <td>0.087463</td>\n",
              "      <td>0.014252</td>\n",
              "      <td>0.156952</td>\n",
              "      <td>-0.078156</td>\n",
              "      <td>-0.177704</td>\n",
              "      <td>0.092926</td>\n",
              "      <td>-0.015839</td>\n",
              "      <td>0.064117</td>\n",
              "      <td>-0.130524</td>\n",
              "      <td>-0.045563</td>\n",
              "      <td>0.039703</td>\n",
              "      <td>0.136902</td>\n",
              "      <td>0.011871</td>\n",
              "      <td>0.015930</td>\n",
              "      <td>-0.123718</td>\n",
              "      <td>0.054565</td>\n",
              "      <td>-0.056244</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>-0.037994</td>\n",
              "      <td>0.080261</td>\n",
              "      <td>-0.024231</td>\n",
              "      <td>-0.150635</td>\n",
              "      <td>-0.049500</td>\n",
              "      <td>0.043701</td>\n",
              "      <td>-0.050781</td>\n",
              "      <td>0.124878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>after rain</td>\n",
              "      <td>aimer</td>\n",
              "      <td>117.453835</td>\n",
              "      <td>-0.010324</td>\n",
              "      <td>0.068620</td>\n",
              "      <td>3.211794</td>\n",
              "      <td>0.147982</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0.088409</td>\n",
              "      <td>0.230469</td>\n",
              "      <td>0.270050</td>\n",
              "      <td>0.196136</td>\n",
              "      <td>0.080658</td>\n",
              "      <td>0.001160</td>\n",
              "      <td>-0.000366</td>\n",
              "      <td>0.056885</td>\n",
              "      <td>0.119629</td>\n",
              "      <td>0.138916</td>\n",
              "      <td>0.092010</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>-0.075134</td>\n",
              "      <td>-0.084290</td>\n",
              "      <td>-0.015533</td>\n",
              "      <td>0.078308</td>\n",
              "      <td>0.135834</td>\n",
              "      <td>0.127350</td>\n",
              "      <td>0.108093</td>\n",
              "      <td>0.130798</td>\n",
              "      <td>0.181519</td>\n",
              "      <td>0.209595</td>\n",
              "      <td>0.181915</td>\n",
              "      <td>0.114105</td>\n",
              "      <td>0.039032</td>\n",
              "      <td>-0.008575</td>\n",
              "      <td>-0.011169</td>\n",
              "      <td>0.006165</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>-0.036346</td>\n",
              "      <td>-0.064331</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002228</td>\n",
              "      <td>0.059570</td>\n",
              "      <td>0.094330</td>\n",
              "      <td>0.083130</td>\n",
              "      <td>0.021271</td>\n",
              "      <td>-0.047668</td>\n",
              "      <td>-0.078918</td>\n",
              "      <td>-0.084808</td>\n",
              "      <td>-0.104095</td>\n",
              "      <td>-0.146606</td>\n",
              "      <td>-0.196167</td>\n",
              "      <td>-0.213898</td>\n",
              "      <td>-0.195343</td>\n",
              "      <td>-0.137665</td>\n",
              "      <td>-0.058563</td>\n",
              "      <td>0.007965</td>\n",
              "      <td>0.031982</td>\n",
              "      <td>0.021088</td>\n",
              "      <td>0.000946</td>\n",
              "      <td>-0.011810</td>\n",
              "      <td>-0.007019</td>\n",
              "      <td>0.011780</td>\n",
              "      <td>0.020172</td>\n",
              "      <td>-0.014740</td>\n",
              "      <td>-0.088257</td>\n",
              "      <td>-0.153931</td>\n",
              "      <td>-0.177551</td>\n",
              "      <td>-0.148010</td>\n",
              "      <td>-0.104492</td>\n",
              "      <td>-0.065399</td>\n",
              "      <td>-0.042267</td>\n",
              "      <td>-0.021881</td>\n",
              "      <td>0.001526</td>\n",
              "      <td>0.030334</td>\n",
              "      <td>0.058197</td>\n",
              "      <td>0.078308</td>\n",
              "      <td>0.087189</td>\n",
              "      <td>0.077271</td>\n",
              "      <td>0.039520</td>\n",
              "      <td>-0.011230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>you he bu ke</td>\n",
              "      <td>xu song</td>\n",
              "      <td>99.384014</td>\n",
              "      <td>0.015339</td>\n",
              "      <td>0.056268</td>\n",
              "      <td>3.166332</td>\n",
              "      <td>0.156298</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.029663</td>\n",
              "      <td>0.032990</td>\n",
              "      <td>0.035187</td>\n",
              "      <td>0.036041</td>\n",
              "      <td>0.036743</td>\n",
              "      <td>0.034882</td>\n",
              "      <td>0.032196</td>\n",
              "      <td>0.030518</td>\n",
              "      <td>0.029724</td>\n",
              "      <td>0.026764</td>\n",
              "      <td>0.022858</td>\n",
              "      <td>0.019684</td>\n",
              "      <td>0.014923</td>\n",
              "      <td>0.006134</td>\n",
              "      <td>-0.003357</td>\n",
              "      <td>-0.010925</td>\n",
              "      <td>-0.015625</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>-0.020020</td>\n",
              "      <td>-0.019958</td>\n",
              "      <td>-0.021667</td>\n",
              "      <td>-0.025299</td>\n",
              "      <td>-0.025970</td>\n",
              "      <td>-0.024109</td>\n",
              "      <td>-0.022125</td>\n",
              "      <td>-0.021271</td>\n",
              "      <td>-0.019287</td>\n",
              "      <td>-0.017853</td>\n",
              "      <td>-0.016998</td>\n",
              "      <td>-0.014557</td>\n",
              "      <td>-0.009460</td>\n",
              "      <td>...</td>\n",
              "      <td>0.166595</td>\n",
              "      <td>0.156311</td>\n",
              "      <td>0.122223</td>\n",
              "      <td>0.115082</td>\n",
              "      <td>0.063934</td>\n",
              "      <td>-0.015839</td>\n",
              "      <td>-0.140503</td>\n",
              "      <td>-0.175171</td>\n",
              "      <td>-0.139526</td>\n",
              "      <td>-0.107880</td>\n",
              "      <td>-0.173096</td>\n",
              "      <td>-0.178223</td>\n",
              "      <td>-0.105835</td>\n",
              "      <td>-0.006348</td>\n",
              "      <td>-0.019012</td>\n",
              "      <td>-0.063751</td>\n",
              "      <td>-0.057861</td>\n",
              "      <td>-0.038025</td>\n",
              "      <td>-0.078644</td>\n",
              "      <td>-0.171570</td>\n",
              "      <td>-0.218201</td>\n",
              "      <td>-0.201263</td>\n",
              "      <td>-0.190277</td>\n",
              "      <td>-0.240173</td>\n",
              "      <td>-0.266998</td>\n",
              "      <td>-0.244324</td>\n",
              "      <td>-0.154602</td>\n",
              "      <td>-0.105103</td>\n",
              "      <td>-0.074249</td>\n",
              "      <td>-0.075378</td>\n",
              "      <td>-0.056458</td>\n",
              "      <td>-0.077820</td>\n",
              "      <td>-0.096558</td>\n",
              "      <td>-0.169525</td>\n",
              "      <td>-0.239258</td>\n",
              "      <td>-0.303772</td>\n",
              "      <td>-0.301147</td>\n",
              "      <td>-0.270264</td>\n",
              "      <td>-0.253265</td>\n",
              "      <td>-0.268066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>youth</td>\n",
              "      <td>troye sivan</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-0.002242</td>\n",
              "      <td>0.056377</td>\n",
              "      <td>3.192966</td>\n",
              "      <td>0.140693</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.131866</td>\n",
              "      <td>-0.142548</td>\n",
              "      <td>-0.052338</td>\n",
              "      <td>-0.129517</td>\n",
              "      <td>-0.023773</td>\n",
              "      <td>-0.067261</td>\n",
              "      <td>-0.056427</td>\n",
              "      <td>-0.040741</td>\n",
              "      <td>-0.012817</td>\n",
              "      <td>-0.019470</td>\n",
              "      <td>0.006042</td>\n",
              "      <td>0.022949</td>\n",
              "      <td>0.013123</td>\n",
              "      <td>0.021088</td>\n",
              "      <td>-0.037201</td>\n",
              "      <td>0.025208</td>\n",
              "      <td>0.002258</td>\n",
              "      <td>0.049225</td>\n",
              "      <td>0.021851</td>\n",
              "      <td>0.064331</td>\n",
              "      <td>0.092194</td>\n",
              "      <td>0.009766</td>\n",
              "      <td>0.036530</td>\n",
              "      <td>0.039917</td>\n",
              "      <td>0.063293</td>\n",
              "      <td>0.069885</td>\n",
              "      <td>0.088470</td>\n",
              "      <td>0.099854</td>\n",
              "      <td>0.110565</td>\n",
              "      <td>0.119507</td>\n",
              "      <td>0.137207</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044128</td>\n",
              "      <td>0.040253</td>\n",
              "      <td>0.043457</td>\n",
              "      <td>0.050812</td>\n",
              "      <td>0.060181</td>\n",
              "      <td>0.071198</td>\n",
              "      <td>0.079681</td>\n",
              "      <td>0.083191</td>\n",
              "      <td>0.083954</td>\n",
              "      <td>0.081451</td>\n",
              "      <td>0.078308</td>\n",
              "      <td>0.077545</td>\n",
              "      <td>0.080292</td>\n",
              "      <td>0.080200</td>\n",
              "      <td>0.075592</td>\n",
              "      <td>0.065704</td>\n",
              "      <td>0.053162</td>\n",
              "      <td>0.028534</td>\n",
              "      <td>-0.004089</td>\n",
              "      <td>-0.015839</td>\n",
              "      <td>-0.020599</td>\n",
              "      <td>-0.022430</td>\n",
              "      <td>-0.013062</td>\n",
              "      <td>-0.004974</td>\n",
              "      <td>-0.008270</td>\n",
              "      <td>-0.020355</td>\n",
              "      <td>-0.030548</td>\n",
              "      <td>-0.039337</td>\n",
              "      <td>-0.049744</td>\n",
              "      <td>-0.054321</td>\n",
              "      <td>-0.050049</td>\n",
              "      <td>-0.041321</td>\n",
              "      <td>-0.036987</td>\n",
              "      <td>-0.037292</td>\n",
              "      <td>-0.043732</td>\n",
              "      <td>-0.052429</td>\n",
              "      <td>-0.064270</td>\n",
              "      <td>-0.074890</td>\n",
              "      <td>-0.081268</td>\n",
              "      <td>-0.086334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>zhe shi ai</td>\n",
              "      <td>henry, donghae</td>\n",
              "      <td>151.999081</td>\n",
              "      <td>-0.020014</td>\n",
              "      <td>0.019520</td>\n",
              "      <td>3.202357</td>\n",
              "      <td>0.075014</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0.011230</td>\n",
              "      <td>0.010864</td>\n",
              "      <td>0.010223</td>\n",
              "      <td>0.009338</td>\n",
              "      <td>0.008270</td>\n",
              "      <td>0.007294</td>\n",
              "      <td>0.006653</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>0.006409</td>\n",
              "      <td>0.006195</td>\n",
              "      <td>0.005402</td>\n",
              "      <td>0.004272</td>\n",
              "      <td>0.003235</td>\n",
              "      <td>0.002563</td>\n",
              "      <td>0.002411</td>\n",
              "      <td>0.002594</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.003204</td>\n",
              "      <td>0.003479</td>\n",
              "      <td>0.003815</td>\n",
              "      <td>0.004181</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.004089</td>\n",
              "      <td>0.003296</td>\n",
              "      <td>0.002350</td>\n",
              "      <td>0.001434</td>\n",
              "      <td>0.000763</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>0.000519</td>\n",
              "      <td>0.000763</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>-0.001190</td>\n",
              "      <td>-0.007141</td>\n",
              "      <td>-0.013306</td>\n",
              "      <td>-0.018616</td>\n",
              "      <td>-0.022339</td>\n",
              "      <td>-0.024353</td>\n",
              "      <td>-0.024902</td>\n",
              "      <td>-0.024414</td>\n",
              "      <td>-0.023132</td>\n",
              "      <td>-0.020477</td>\n",
              "      <td>-0.016113</td>\n",
              "      <td>-0.010834</td>\n",
              "      <td>-0.006073</td>\n",
              "      <td>-0.002625</td>\n",
              "      <td>-0.000549</td>\n",
              "      <td>0.000916</td>\n",
              "      <td>0.002197</td>\n",
              "      <td>0.003082</td>\n",
              "      <td>0.003418</td>\n",
              "      <td>0.003021</td>\n",
              "      <td>0.001007</td>\n",
              "      <td>-0.003113</td>\n",
              "      <td>-0.007629</td>\n",
              "      <td>-0.009796</td>\n",
              "      <td>-0.009186</td>\n",
              "      <td>-0.007812</td>\n",
              "      <td>-0.007507</td>\n",
              "      <td>-0.007812</td>\n",
              "      <td>-0.007477</td>\n",
              "      <td>-0.006134</td>\n",
              "      <td>-0.004395</td>\n",
              "      <td>-0.002441</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>-0.001984</td>\n",
              "      <td>-0.006317</td>\n",
              "      <td>-0.010193</td>\n",
              "      <td>-0.011780</td>\n",
              "      <td>-0.011963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>zui mei hun li</td>\n",
              "      <td>bai xiao bai</td>\n",
              "      <td>112.347147</td>\n",
              "      <td>0.022650</td>\n",
              "      <td>0.051512</td>\n",
              "      <td>3.168251</td>\n",
              "      <td>0.134493</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.006927</td>\n",
              "      <td>-0.005676</td>\n",
              "      <td>-0.004700</td>\n",
              "      <td>-0.005310</td>\n",
              "      <td>-0.004791</td>\n",
              "      <td>-0.003937</td>\n",
              "      <td>-0.003296</td>\n",
              "      <td>-0.001343</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>-0.000885</td>\n",
              "      <td>-0.001007</td>\n",
              "      <td>-0.001312</td>\n",
              "      <td>-0.000580</td>\n",
              "      <td>-0.000092</td>\n",
              "      <td>-0.000671</td>\n",
              "      <td>-0.001343</td>\n",
              "      <td>-0.002991</td>\n",
              "      <td>-0.003540</td>\n",
              "      <td>-0.001953</td>\n",
              "      <td>-0.001678</td>\n",
              "      <td>-0.001801</td>\n",
              "      <td>-0.000732</td>\n",
              "      <td>0.000519</td>\n",
              "      <td>0.001007</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>-0.000275</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>-0.000427</td>\n",
              "      <td>-0.000916</td>\n",
              "      <td>-0.001404</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.091461</td>\n",
              "      <td>-0.129303</td>\n",
              "      <td>-0.136017</td>\n",
              "      <td>-0.235016</td>\n",
              "      <td>-0.308197</td>\n",
              "      <td>-0.283325</td>\n",
              "      <td>-0.336334</td>\n",
              "      <td>-0.326294</td>\n",
              "      <td>-0.367371</td>\n",
              "      <td>-0.401154</td>\n",
              "      <td>-0.385101</td>\n",
              "      <td>-0.277771</td>\n",
              "      <td>-0.209900</td>\n",
              "      <td>-0.194763</td>\n",
              "      <td>-0.103821</td>\n",
              "      <td>-0.030243</td>\n",
              "      <td>0.045837</td>\n",
              "      <td>0.050049</td>\n",
              "      <td>0.033478</td>\n",
              "      <td>-0.007080</td>\n",
              "      <td>0.012207</td>\n",
              "      <td>-0.076447</td>\n",
              "      <td>-0.086456</td>\n",
              "      <td>-0.116547</td>\n",
              "      <td>-0.174988</td>\n",
              "      <td>-0.156281</td>\n",
              "      <td>-0.093628</td>\n",
              "      <td>-0.032257</td>\n",
              "      <td>-0.046265</td>\n",
              "      <td>0.022491</td>\n",
              "      <td>0.065247</td>\n",
              "      <td>0.098297</td>\n",
              "      <td>0.120911</td>\n",
              "      <td>0.100739</td>\n",
              "      <td>0.036255</td>\n",
              "      <td>-0.002991</td>\n",
              "      <td>-0.016052</td>\n",
              "      <td>-0.074615</td>\n",
              "      <td>-0.111176</td>\n",
              "      <td>-0.077942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>zurui yo</td>\n",
              "      <td>chihiro</td>\n",
              "      <td>161.499023</td>\n",
              "      <td>0.001965</td>\n",
              "      <td>0.047713</td>\n",
              "      <td>3.181779</td>\n",
              "      <td>0.129770</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.142670</td>\n",
              "      <td>0.004974</td>\n",
              "      <td>0.069397</td>\n",
              "      <td>0.037872</td>\n",
              "      <td>0.081940</td>\n",
              "      <td>0.245605</td>\n",
              "      <td>0.166901</td>\n",
              "      <td>0.177002</td>\n",
              "      <td>0.122192</td>\n",
              "      <td>0.111298</td>\n",
              "      <td>-0.072601</td>\n",
              "      <td>-0.212158</td>\n",
              "      <td>-0.215820</td>\n",
              "      <td>-0.235107</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>-0.380890</td>\n",
              "      <td>-0.293121</td>\n",
              "      <td>-0.207977</td>\n",
              "      <td>-0.147064</td>\n",
              "      <td>-0.018707</td>\n",
              "      <td>0.130798</td>\n",
              "      <td>0.090454</td>\n",
              "      <td>0.140869</td>\n",
              "      <td>0.113464</td>\n",
              "      <td>0.121368</td>\n",
              "      <td>-0.059479</td>\n",
              "      <td>-0.034119</td>\n",
              "      <td>-0.035553</td>\n",
              "      <td>-0.121796</td>\n",
              "      <td>-0.010925</td>\n",
              "      <td>-0.091125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.082886</td>\n",
              "      <td>0.143158</td>\n",
              "      <td>0.176758</td>\n",
              "      <td>0.211060</td>\n",
              "      <td>0.234467</td>\n",
              "      <td>0.255554</td>\n",
              "      <td>0.279510</td>\n",
              "      <td>0.266266</td>\n",
              "      <td>0.272156</td>\n",
              "      <td>0.264038</td>\n",
              "      <td>0.259674</td>\n",
              "      <td>0.199188</td>\n",
              "      <td>0.161713</td>\n",
              "      <td>0.115631</td>\n",
              "      <td>0.072113</td>\n",
              "      <td>0.068176</td>\n",
              "      <td>0.003723</td>\n",
              "      <td>-0.035675</td>\n",
              "      <td>-0.076721</td>\n",
              "      <td>-0.078918</td>\n",
              "      <td>-0.115356</td>\n",
              "      <td>-0.121521</td>\n",
              "      <td>-0.140930</td>\n",
              "      <td>-0.141907</td>\n",
              "      <td>-0.128998</td>\n",
              "      <td>-0.180969</td>\n",
              "      <td>-0.182861</td>\n",
              "      <td>-0.190491</td>\n",
              "      <td>-0.225159</td>\n",
              "      <td>-0.191071</td>\n",
              "      <td>-0.165710</td>\n",
              "      <td>-0.166901</td>\n",
              "      <td>-0.168793</td>\n",
              "      <td>-0.157715</td>\n",
              "      <td>-0.123444</td>\n",
              "      <td>-0.102936</td>\n",
              "      <td>-0.092194</td>\n",
              "      <td>-0.076324</td>\n",
              "      <td>-0.026764</td>\n",
              "      <td>0.004791</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 100009 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                title              artist  ...     99998     99999\n",
              "0     a new adventure  takanashi yasuharu  ...  0.183716  0.136566\n",
              "1                a oh        super junior  ...  0.071136  0.130554\n",
              "2    a thousand years     christina perri  ... -0.029633 -0.027527\n",
              "3             adore u           seventeen  ... -0.050781  0.124878\n",
              "4          after rain               aimer  ...  0.039520 -0.011230\n",
              "..                ...                 ...  ...       ...       ...\n",
              "195      you he bu ke             xu song  ... -0.253265 -0.268066\n",
              "196             youth         troye sivan  ... -0.081268 -0.086334\n",
              "197        zhe shi ai      henry, donghae  ... -0.011780 -0.011963\n",
              "198    zui mei hun li        bai xiao bai  ... -0.111176 -0.077942\n",
              "199          zurui yo             chihiro  ... -0.026764  0.004791\n",
              "\n",
              "[200 rows x 100009 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqOdOhgUOJRg"
      },
      "source": [
        "def build_xy(features):\n",
        "    x = features.iloc[:, 9:]\n",
        "    y = features[['primary', 'secondary']]\n",
        "    y['combined'] = y['primary'].astype(str) + y['secondary'].astype(str)\n",
        "    return (x, y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnYgFoDgFQ_T",
        "outputId": "abac193e-d497-4150-c723-7c6b8ca32da9"
      },
      "source": [
        "# Multi-Layer Perceptron with raw features\n",
        "x, y = build_xy(combined_raw)\n",
        "mlp_model = neural_network.MLPClassifier()\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "pca = decomposition.PCA(n_components = 0.95, svd_solver = \"full\")\n",
        "pipe = pipeline.Pipeline(steps = [('scaler', scaler), ('pca', pca), ('mlp', mlp_model)])\n",
        "param_grid = {\n",
        "    'mlp__hidden_layer_sizes': [(2000,)],\n",
        "}\n",
        "model = model_selection.GridSearchCV(pipe, param_grid, cv = 5)\n",
        "# model.fit(x, y['primary'])\n",
        "# print (\"***SVM Best Parameters***\")\n",
        "# print (model.best_params_)\n",
        "accuracies = model_selection.cross_val_score(model, x, y['primary'], cv = 5)\n",
        "print(\"Average accuracy:\", np.mean(accuracies))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average accuracy: 0.215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_10fYypJxHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970a9bf0-5dee-448c-ce3a-995417e68c50"
      },
      "source": [
        "print(\"Average accuracy:\", np.mean(accuracies))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average accuracy: 0.21000000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}