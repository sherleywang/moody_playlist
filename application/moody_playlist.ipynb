{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "compound-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out warnings import when testing is done\n",
    "import warnings\n",
    "# import packages\n",
    "import librosa\n",
    "import pyAudioAnalysis as pyaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from tkinter.ttk import Progressbar\n",
    "from tkinter.ttk import Button\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import MidTermFeatures\n",
    "import copy\n",
    "import ntpath\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continuous-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toggle warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "persistent-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select the location of the mp3 files\n",
    "root = tkinter.Tk()\n",
    "root.withdraw()\n",
    "root.directory = filedialog.askdirectory(message = \"Select the folder containing the MP3 files.\")\n",
    "path = root.directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "patient-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "changing-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress = Progressbar(root, length = 100, mode = 'determinate')\n",
    "# progress.pack()\n",
    "# Button(root, text = 'Progress of Generating Playlists').pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "legitimate-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3u_paths = {}\n",
    "librosa_features = {}\n",
    "pyaudio_features = {}\n",
    "feat_names = None\n",
    "\n",
    "for root, dirs, files in os.walk(path, topdown = False):\n",
    "    mid_term_window = 1\n",
    "    mid_term_step = 1\n",
    "    short_term_window = 0.05\n",
    "    short_term_step = 0.05\n",
    "    pyaudio_feat, song_files, feat_names = MidTermFeatures.directory_feature_extraction(root, \n",
    "                                                                                        mid_term_window, \n",
    "                                                                                        mid_term_step, \n",
    "                                                                                        short_term_window, \n",
    "                                                                                        short_term_step,\n",
    "                                                                                        False)\n",
    "    counter = 0\n",
    "    for s in song_files:\n",
    "        s_dict_name = ntpath.basename(s)\n",
    "        if pyaudio_feat.ndim == 1:\n",
    "            pyaudio_features[s_dict_name] = pyaudio_feat\n",
    "        else:\n",
    "            pyaudio_features[s_dict_name] = pyaudio_feat[counter]\n",
    "        counter += 1\n",
    "\n",
    "    for folder in dirs:\n",
    "        folder_path = os.path.join(root, folder)\n",
    "        pyaudio_feat, song_files, feat_names = MidTermFeatures.directory_feature_extraction(folder_path, \n",
    "                                                                                            mid_term_window, \n",
    "                                                                                            mid_term_step, \n",
    "                                                                                            short_term_window, \n",
    "                                                                                            short_term_step,\n",
    "                                                                                            False)\n",
    "        counter = 0\n",
    "        for s in song_files:\n",
    "            s_dict_name = ntpath.basename(s)\n",
    "            if pyaudio_feat.ndim == 1:\n",
    "                pyaudio_features[s_dict_name] = pyaudio_feat\n",
    "            else:\n",
    "                pyaudio_features[s_dict_name] = pyaudio_feat[counter]\n",
    "            counter += 1\n",
    "    \n",
    "    for song in files:\n",
    "        song_path = os.path.join(root, song)\n",
    "        if song_path.endswith(\".mp3\"):\n",
    "            # get the tempo of the song\n",
    "            waveform, samp_rate = librosa.load(song_path)\n",
    "            tempo, beat_frames = librosa.beat.beat_track(waveform, samp_rate)\n",
    "\n",
    "            # get the chroma number of the song\n",
    "            beat_times = librosa.frames_to_time(beat_frames, samp_rate)\n",
    "            y_harmonic, y_percussive = librosa.effects.hpss(waveform)\n",
    "            chromagram = librosa.feature.chroma_cqt(y_harmonic, samp_rate)\n",
    "            beat_chroma = librosa.util.sync(chromagram, beat_frames, aggregate = np.median)\n",
    "            # make beat chroma into a DataFrame and calculate the diff\n",
    "            chroma_df = pd.DataFrame(beat_chroma)\n",
    "            diff_values = chroma_df.diff()\n",
    "            diff_mean = diff_values.mean(axis = 0, skipna = True)\n",
    "            chroma_num = sum(diff_mean) / len(diff_mean)\n",
    "            librosa_features[song] = [tempo, chroma_num]\n",
    "            m3u_paths[song] = song_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the extraction of both sets of features is successful\n",
    "if len(pyaudio_features) != len(librosa_features):\n",
    "    messagebox.showinfo(\"Error\", \"Import of MP3 files failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "passing-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep desired features from pyAudioAnalysis for stacked classifier\n",
    "new_pyaudio_features = {}\n",
    "selected_feats = ['zcr_mean', 'zcr_std', 'energy_mean', 'energy_entropy_mean', 'spectral_centroid_mean', \n",
    "                  'spectral_spread_mean', 'spectral_entropy_mean', 'mfcc_2_mean', 'mfcc_5_mean', 'mfcc_6_mean',\n",
    "                  'spectral_centroid_std', 'spectral_entropy_std', 'spectral_spread_std', 'chroma_7_std',\n",
    "                  'delta chroma_2_std', 'delta chroma_3_std', 'delta chroma_9_std', 'delta chroma_std_std',\n",
    "                  'delta energy_std', 'delta mfcc_1_std', 'delta mfcc_3_std', 'delta mfcc_13_std',\n",
    "                  'delta spectral_centroid_std', 'delta spectral_entropy_std', 'delta spectral_flux_std',\n",
    "                  'delta spectral_spread_std']\n",
    "for key, value in pyaudio_features.items():\n",
    "    index_list = [feat_names.index(feat) for feat in selected_feats]\n",
    "    extracted_feats = [value[i] for i in index_list]\n",
    "    new_pyaudio_features[key] = extracted_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "severe-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose and merge the engineered features into one feature DataFrame\n",
    "librosa_df = pd.DataFrame(librosa_features)\n",
    "librosa_df = librosa_df.transpose()\n",
    "eng_pyaudio_df = pd.DataFrame(new_pyaudio_features)\n",
    "eng_pyaudio_df = eng_pyaudio_df.transpose()\n",
    "eng_features = librosa_df.merge(eng_pyaudio_df, right_index = True, left_index = True)\n",
    "eng_features.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "classified-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate neural network features\n",
    "pyaudio_df = pd.DataFrame(pyaudio_features)\n",
    "pyaudio_df = pyaudio_df.transpose()\n",
    "nn_features = pyaudio_df\n",
    "nn_features.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "drawn-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the stacking model and predict using the engineered features\n",
    "loaded_stacker = pickle.load(open('mood_stacking_model.sav', 'rb'))\n",
    "stacker_predictions = loaded_stacker.predict(eng_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "thorough-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mlp model and predict using the neural network features\n",
    "loaded_mlp = pickle.load(open('mood_mlp_model.sav', 'rb'))\n",
    "mlp_predictions = loaded_mlp.predict(nn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "expected-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine predictions for a final prediction\n",
    "final_preds = []\n",
    "\n",
    "for i in range(len(stacker_predictions)):\n",
    "    stack_pred = stacker_predictions[i]\n",
    "    mlp_pred = mlp_predictions[i]\n",
    "    \n",
    "    if stack_pred != mlp_pred:\n",
    "        # prediction was different between stacking and mlp models\n",
    "        if stack_pred == 1 or stack_pred == 3:\n",
    "            # prefer stacking classifier for moods 1 and 3\n",
    "            final_preds.append(stack_pred)\n",
    "        else:\n",
    "            final_preds.append(mlp_pred)\n",
    "    else:\n",
    "        # predictions are the same, just append mlp's prediction\n",
    "        final_preds.append(mlp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "accessory-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate song lists based on predicted moods\n",
    "# 1 epic, 2 lighthearted, 3 energetic, 4 calm, 5 chill, 6 miscellaneous\n",
    "epic = []\n",
    "lighthearted = []\n",
    "energetic = []\n",
    "calm = []\n",
    "chill = []\n",
    "miscellaneous = []\n",
    "\n",
    "# ordering of indices are the same since indices are sorted before passed into the models\n",
    "for i in range(len(final_preds)):\n",
    "    song = eng_features.index[i]\n",
    "    pred = final_preds[i]\n",
    "    if pred == 1:\n",
    "        epic.append(song)\n",
    "    if pred == 2:\n",
    "        lighthearted.append(song)\n",
    "    if pred == 3:\n",
    "        energetic.append(song)\n",
    "    if pred == 4:\n",
    "        calm.append(song)\n",
    "    if pred == 5:\n",
    "        chill.append(song)\n",
    "    if pred == 6:\n",
    "        miscellaneous.append(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "numerous-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3u_paths_relative = {}\n",
    "for key, value in m3u_paths.items():\n",
    "    root_length = len(path) + 1\n",
    "    m3u_paths_relative[key] = value[root_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "opposed-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_playlist(path, filename, mood_list):\n",
    "    full_path = path + \"/\" + filename + \".m3u\"\n",
    "    file = open(full_path, \"w\")\n",
    "    playlist = [m3u_paths_relative[song] + \"\\n\" for song in mood_list]\n",
    "    playlist.insert(0, \"#EXTM3U\\n\")\n",
    "    file.writelines(playlist)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "based-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_playlist(path, \"epic_playlist\", epic)\n",
    "write_playlist(path, \"lighthearted_playlist\", lighthearted)\n",
    "write_playlist(path, \"energetic_playlist\", energetic)\n",
    "write_playlist(path, \"calm_playlist\", calm)\n",
    "write_playlist(path, \"chill_playlist\", chill)\n",
    "write_playlist(path, \"miscellaneous_playlist\", miscellaneous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "collaborative-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "time_elapsed = round((end - start) / 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "driven-interim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"Total Time Elapsed: \" + str(time_elapsed) + \" minutes\"\n",
    "messagebox.showinfo(\"Playlists have been successfully created.\", message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-applicant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
