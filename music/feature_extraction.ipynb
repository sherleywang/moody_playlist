{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import general packages\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyAudioAnalysis package utility\n",
    "import pyAudioAnalysis as pyaudio\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import MidTermFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction data structures\n",
    "features = []\n",
    "existing = []\n",
    "missing = []\n",
    "prev_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and save existing basic features\n",
    "if os.path.exists(\"../data/features.csv\"):\n",
    "    prev_features = pd.read_csv(\"../data/features.csv\")\n",
    "    # drop all rows with any number of NAs\n",
    "    prev_features.dropna(how = 'any')\n",
    "    prev_features['song'] = prev_features['title'] + \" - \" + prev_features['artist']\n",
    "    existing = prev_features['song'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction notebook should be in the same folder as the mp3s\n",
    "for song in os.scandir(\".\"):\n",
    "    if song.path.endswith(\".mp3\") and song.is_file():\n",
    "        # skip ./ in the path to the mp3 file\n",
    "        file_name = song.path[2:]\n",
    "        song_name = file_name[:len(file_name) - 4]\n",
    "        \n",
    "        if song_name not in existing:\n",
    "            # add it to the missing list so we can use pyAudioAnalysis on it\n",
    "            missing.append(file_name)\n",
    "            \n",
    "            # get the tempo of the song\n",
    "            waveform, samp_rate = librosa.load(file_name)\n",
    "            tempo, beat_frames = librosa.beat.beat_track(waveform, samp_rate)\n",
    "\n",
    "            # get the chroma number of the song\n",
    "            beat_times = librosa.frames_to_time(beat_frames, samp_rate)\n",
    "            y_harmonic, y_percussive = librosa.effects.hpss(waveform)\n",
    "            chromagram = librosa.feature.chroma_cqt(y_harmonic, samp_rate)\n",
    "            beat_chroma = librosa.util.sync(chromagram, beat_frames, aggregate = np.median)\n",
    "            # make beat chroma into a DataFrame and calculate the diff\n",
    "            chroma_df = pd.DataFrame(beat_chroma)\n",
    "            diff_values = chroma_df.diff()\n",
    "            diff_mean = diff_values.mean(axis = 0, skipna = True)\n",
    "            chroma_num = sum(diff_mean) / len(diff_mean)\n",
    "\n",
    "            # add song, tempo and chroma number to the features list\n",
    "            print ([song_name, tempo, chroma_num])\n",
    "            features.append([song_name, tempo, chroma_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the features DataFrame alphabetically by song name\n",
    "features_df = pd.DataFrame(features, columns = ['song', 'tempo', 'chroma_number'])\n",
    "features_df = features_df.sort_values(by = ['song'])\n",
    "features_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move all the mp3 files that need to have features extracted into some folder\n",
    "with open('missing.txt', 'w+') as f:\n",
    "    for song in missing:\n",
    "        f.write(\"%s\\n\" % song)\n",
    "# use command line here\n",
    "'''\n",
    "mkdir missing\n",
    "cat missing.txt | while read line\n",
    "do\n",
    "    cp $line missing\n",
    "done\n",
    "'''\n",
    "# make sure to change the path in directory_feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pyAudioAnalysis features\n",
    "mid_term_window = 1\n",
    "mid_term_step = 1\n",
    "short_term_window = 0.05\n",
    "short_term_step = 0.05\n",
    "# use compute_beat = True if we want the extra beat features\n",
    "pyaudio_feat, files, feat_names = MidTermFeatures.directory_feature_extraction(\".\", \n",
    "                                                                               mid_term_window, \n",
    "                                                                               mid_term_step, \n",
    "                                                                               short_term_window, \n",
    "                                                                               short_term_step,\n",
    "                                                                               False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pyAudioAnalysis features as neural network features\n",
    "if len(features_df) == 1:\n",
    "    # special case when only features from one song are extracted\n",
    "    nn_features_df = pd.DataFrame([pyaudio_feat], columns = feat_names)\n",
    "else:\n",
    "    nn_features_df = pd.DataFrame(pyaudio_feat, columns = feat_names)\n",
    "nn_features_df['song'] = features_df['song']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the basic features by indexing into the neural network feature DataFrame\n",
    "zcr_ind = feat_names.index('zcr_mean')\n",
    "ee_ind = feat_names.index('energy_entropy_mean')\n",
    "spc_ind = feat_names.index('spectral_centroid_mean')\n",
    "\n",
    "features_df['zero_crossing_rate'] = nn_features_df.iloc[:, zcr_ind]\n",
    "features_df['energy_entropy'] = nn_features_df.iloc[:, ee_ind]\n",
    "features_df['spectral_centroid'] = nn_features_df.iloc[:, spc_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mood label data\n",
    "moods = pd.read_csv(\"../data/mood_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the features with the mood label data\n",
    "moods['song'] = moods['title'] + \" - \" + moods['artist']\n",
    "# sort the column song to use it for merging\n",
    "moods = moods.sort_values(by = ['song'])\n",
    "moods.reset_index(drop = True, inplace = True)\n",
    "\n",
    "new_features = features_df.merge(moods, on = \"song\", how = \"left\")\n",
    "new_features = new_features.drop(columns = ['song'])\n",
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the basic features, neural network features and the feature names\n",
    "if not existing:\n",
    "    new_features = new_features[['title', 'artist', 'tempo', 'chroma_number', \n",
    "                                 'zero_crossing_rate', 'energy_entropy', \n",
    "                                 'spectral_centroid', 'primary', 'secondary']]\n",
    "    new_features.to_csv(\"../data/features.csv\", header = True, index = False)\n",
    "    \n",
    "    nn_features_df.to_csv(\"../data/nn_features.csv\", header = True, index = False)\n",
    "    \n",
    "    feat_names_df = pd.DataFrame(feat_names)\n",
    "    feat_names_df.to_csv(\"../data/nn_feature_names.csv\", header = True, index = False)\n",
    "else:\n",
    "    # concatenate the previous features with new features and overwrite the existing files\n",
    "    prev_features = prev_features.drop(columns = ['song'])\n",
    "    all_features = pd.concat([prev_features, new_features], ignore_index = True)\n",
    "    all_features = all_features[['title', 'artist', 'tempo', 'chroma_number', \n",
    "                                 'zero_crossing_rate', 'energy_entropy', \n",
    "                                 'spectral_centroid', 'primary', 'secondary']]\n",
    "    all_features.to_csv(\"../data/features.csv\", header = True, index = False)\n",
    "    \n",
    "    prev_nn = pd.read_csv(\"../data/nn_features.csv\")\n",
    "    all_nn = pd.concat([prev_nn, nn_features_df], ignore_index = True)\n",
    "    all_nn.to_csv(\"../data/nn_features.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to delete the directory missing and the text file missing.txt\n",
    "'''\n",
    "rm -r missing\n",
    "rm missing.txt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "feat_names_df = pd.read_csv(\"../data/nn_feature_names.csv\")\n",
    "current_features = pd.read_csv(\"../data/features.csv\")\n",
    "feats_to_extract = pd.read_csv(\"../data/nn_features.csv\")\n",
    "engineered_features = current_features[['title', 'artist', 'tempo', 'chroma_number']]\n",
    "\n",
    "# check that the ordering of songs is the same\n",
    "engineered_features['song'] = feats_to_extract['song']\n",
    "engineered_features['song_check'] = engineered_features['title'] + ' - ' + engineered_features['artist']\n",
    "if engineered_features['song'].equals(engineered_features['song_check']):\n",
    "    print (\"Song ordering matches.\")\n",
    "    engineered_features = engineered_features.drop(columns = ['song', 'song_check'])\n",
    "else:\n",
    "    print (\"Song ordering DOES NOT match.\")\n",
    "\n",
    "# convert the feature names into a list\n",
    "feat_names_list = feat_names_df['0'].to_list()\n",
    "# selected 28 total features based on distribution boxplots by primary mood\n",
    "selected_feats = ['zcr_mean', 'zcr_std', 'energy_mean', 'energy_entropy_mean', 'spectral_centroid_mean', \n",
    "                  'spectral_spread_mean', 'spectral_entropy_mean', 'mfcc_2_mean', 'mfcc_5_mean', 'mfcc_6_mean',\n",
    "                  'spectral_centroid_std', 'spectral_entropy_std', 'spectral_spread_std', 'chroma_7_std',\n",
    "                  'delta chroma_2_std', 'delta chroma_3_std', 'delta chroma_9_std', 'delta chroma_std_std',\n",
    "                  'delta energy_std', 'delta mfcc_1_std', 'delta mfcc_3_std', 'delta mfcc_13_std',\n",
    "                  'delta spectral_centroid_std', 'delta spectral_entropy_std', 'delta spectral_flux_std',\n",
    "                  'delta spectral_spread_std']\n",
    "for feat in selected_feats:\n",
    "    engineered_features[feat] = feats_to_extract.iloc[:, feat_names_list.index(feat)]\n",
    "\n",
    "# add mood labels to the final features dataframe\n",
    "engineered_features['primary'] = current_features['primary']\n",
    "engineered_features['secondary'] = current_features['secondary']\n",
    "\n",
    "# save the engineered features\n",
    "engineered_features.to_csv(\"../data/engineered_features.csv\", header = True, index = False)\n",
    "engineered_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
